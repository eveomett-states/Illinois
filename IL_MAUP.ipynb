{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to MAUP\n",
    "@author: eveomett\n",
    "AI for Redistricting, USF\n",
    "All data retrieved 11/21/23: <br>\n",
    "    [https://redistrictingdatahub.org/dataset/illinois-block-pl-94171-2020-by-table/](https://redistrictingdatahub.org/dataset/illinois-block-pl-94171-2020-by-table/) <br>\n",
    "    [https://redistrictingdatahub.org/dataset/vest-2020-illinois-precinct-and-election-results/](https://redistrictingdatahub.org/dataset/vest-2020-illinois-precinct-and-election-results/) <br>\n",
    "    [https://redistrictingdatahub.org/dataset/2021-illinois-congressional-districts-approved-plan/](https://redistrictingdatahub.org/dataset/2021-illinois-congressional-districts-approved-plan/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import maup\n",
    "import time\n",
    "from maup import smart_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "maup.progress.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is useful for the data below:<br>\n",
    "[https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/summary-file/2020Census_PL94_171Redistricting_StatesTechDoc_English.pdf](https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/summary-file/2020Census_PL94_171Redistricting_StatesTechDoc_English.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "Note: importing the census data takes 4-5 minutes per file.  The other fi#### This first census file has population, Hispanic and non-Hispanic details.les are faster. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This first census file has total population of different races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to import il_pl2020_p1_b.shp is: 1.8158757170041402 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "population1_df = gpd.read_file(\"./il_pl2020_b/il_pl2020_p1_b.shp\")\n",
    "end_time = time.time()\n",
    "print(\"The time to import il_pl2020_p1_b.shp is:\",\n",
    "      (end_time-start_time)/60, \"mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This second census file has population, Hispanic and non-Hispanic details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to import il_pl2020_p2_b.shp is: 1.5123519817988078 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "population2_df = gpd.read_file(\"./il_pl2020_b/il_pl2020_p2_b.shp\")\n",
    "end_time = time.time()\n",
    "print(\"The time to import il_pl2020_p2_b.shp is:\",\n",
    "      (end_time-start_time)/60, \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "population2_df = population2_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.merge(population1_df, population2_df, on='GEOID20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEOID20', 'SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'P0010001',\n",
       "       'P0010002', 'P0010003', 'P0010004', 'P0010005', 'P0010006', 'P0010007',\n",
       "       'P0010008', 'P0010009', 'P0010010', 'P0010011', 'P0010012', 'P0010013',\n",
       "       'P0010014', 'P0010015', 'P0010016', 'P0010017', 'P0010018', 'P0010019',\n",
       "       'P0010020', 'P0010021', 'P0010022', 'P0010023', 'P0010024', 'P0010025',\n",
       "       'P0010026', 'P0010027', 'P0010028', 'P0010029', 'P0010030', 'P0010031',\n",
       "       'P0010032', 'P0010033', 'P0010034', 'P0010035', 'P0010036', 'P0010037',\n",
       "       'P0010038', 'P0010039', 'P0010040', 'P0010041', 'P0010042', 'P0010043',\n",
       "       'P0010044', 'P0010045', 'P0010046', 'P0010047', 'P0010048', 'P0010049',\n",
       "       'P0010050', 'P0010051', 'P0010052', 'P0010053', 'P0010054', 'P0010055',\n",
       "       'P0010056', 'P0010057', 'P0010058', 'P0010059', 'P0010060', 'P0010061',\n",
       "       'P0010062', 'P0010063', 'P0010064', 'P0010065', 'P0010066', 'P0010067',\n",
       "       'P0010068', 'P0010069', 'P0010070', 'P0010071', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population1_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hispanic = total - non-hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df['H_WHITE'] = population_df.apply(lambda t: t['P0010003'] - t['P0020005'], 1)\n",
    "population_df['H_BLACK'] = population_df.apply(lambda t: t['P0010004'] - t['P0020006'], 1)\n",
    "population_df['H_AMIN'] = population_df.apply(lambda t: t['P0010005'] - t['P0020007'], 1)\n",
    "population_df['H_ASIAN'] = population_df.apply(lambda t: t['P0010006'] - t['P0020008'], 1)\n",
    "population_df['H_NHPI'] = population_df.apply(lambda t: t['P0010007'] - t['P0020009'], 1)\n",
    "population_df['H_OTHER'] = population_df.apply(lambda t: t['P0010008'] - t['P0020010'], 1)\n",
    "population_df['H_2MORE'] = population_df.apply(lambda t: t['P0010009'] - t['P0020011'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third census file has voting age population (VAP), Hispanic and non-Hispanic details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to import il_pl2020_p4_b.shp is: 1.270311999320984 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "vap_df= gpd.read_file(\"./il_pl2020_b/il_pl2020_p4_b.shp\")\n",
    "end_time = time.time()\n",
    "print(\"The time to import il_pl2020_p4_b.shp is:\",\n",
    "      (end_time-start_time)/60, \"mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 election data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set below has 2020 presidential election results by precinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to import il_vest_20.shp is: 0.03718810081481934 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "vest20 = gpd.read_file(\"./il_vest_20/il_vest_20.shp\")\n",
    "end_time = time.time()\n",
    "print(\"The time to import il_vest_20.shp is:\",\n",
    "      (end_time-start_time)/60, \"mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Put data in same geometry units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll assign blocks to precints <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10083/10083 [00:32<00:00, 310.03it/s]\n",
      "100%|█████████████████████████████████████████| 10083/10083 [00:02<00:00, 3418.82it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n",
      "100%|██████████████████████████████████████████| 10083/10083 [00:29<00:00, 342.35it/s]\n",
      "100%|█████████████████████████████████████████| 10083/10083 [00:02<00:00, 3443.20it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "blocks_to_precincts_assignment = maup.assign(population_df.geometry, vest20.geometry)\n",
    "vap_blocks_to_precincts_assignment = maup.assign(vap_df.geometry, vest20.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns below are the ones we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_column_names = ['P0020001', 'P0020002', 'P0020005', 'P0020006', 'P0020007', 'P0020008', 'P0020009', 'P0020010', 'P0020011', \n",
    "                    'H_WHITE', 'H_BLACK', 'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "vap_column_names = ['P0040001', 'P0040002', 'P0040005', 'P0040006', 'P0040007', 'P0040008', 'P0040009', 'P0040010', 'P0040011']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put all of the population columns into the election dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vest20[pop_column_names] = population_df[pop_column_names].groupby(blocks_to_precincts_assignment).sum()\n",
    "vest20[vap_column_names] = vap_df[vap_column_names].groupby(vap_blocks_to_precincts_assignment).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to make sure we didn't lose anyone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method maup.doctor() outputs true if geometries look OK.  False if there are gaps or overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10083/10083 [00:11<00:00, 846.85it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/repair.py:331: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  overlaps = inters[inters.area > 0].make_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(maup.doctor(vest20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional District data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set below is a shapefile of the congressional districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to import HB 1291 FA #1.shp is: 0.003995637098948161 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cong_df = gpd.read_file(\"./il_cong_adopted_2021/HB 1291 FA #1.shp\")\n",
    "end_time = time.time()\n",
    "print(\"The time to import HB 1291 FA #1.shp is:\",\n",
    "      (end_time-start_time)/60, \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 17/17 [00:00<00:00, 36.35it/s]\n",
      "100%|█████████████████████████████████████████████████| 17/17 [00:24<00:00,  1.45s/it]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "precincts_to_districts_assignment = maup.assign(vest20.geometry, cong_df.geometry)\n",
    "vest20[\"CD\"] = precincts_to_districts_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n"
     ]
    }
   ],
   "source": [
    "print(set(vest20[\"CD\"]))\n",
    "# for precinct_index in range(len(vest20)):\n",
    "#     vest20.at[precinct_index, \"CD\"] = cong_df.at[vest20.at[precinct_index, \"CD\"], district_col_name]\n",
    "vest20['CD'] = vest20['CD'].apply(lambda t: t + 1)\n",
    "print(set(cong_df[district_col_name]))\n",
    "print(set(vest20[\"CD\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senate House data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = gpd.read_file(\"./il_sldu_2021/il_sldu_2021.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 59/59 [00:00<00:00, 129.42it/s]\n",
      "100%|█████████████████████████████████████████████████| 59/59 [00:12<00:00,  4.88it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "precincts_to_send_assignment = maup.assign(vest20.geometry, send.geometry)\n",
    "vest20[\"SEND\"] = precincts_to_send_assignment.apply(lambda t: t + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State house data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist = gpd.read_file(\"./il_sldl_adopted_2021/il_sldl_adopted_2021.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use maup.quick_repair() or maup.smart_repair() if there are problems.\\\n",
    "Before smart_repair(), we need to use gdf.estimate_utm_crs() to change it to a utm crs.\\\n",
    "Then, use maup.doctor() to make sure that the overlap is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist = hdist.to_crs(hdist.estimate_utm_crs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:95: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = shapely.wkb.loads(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:149: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][i] = make_valid(geometries_df[\"geometry\"][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:372: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  pieces_df[\"polygon indices\"][i] = set()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                         | 0/119 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:415: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  pieces_df[\"polygon indices\"][i] = pieces_df[\"polygon indices\"][i].union({j})\n",
      "100%|█████████████████████████████████████████████| 119/119 [00:00<00:00, 1114.61it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:487: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"geometry\"][this_poly_ind] = unary_union([geometries_df[\"geometry\"][this_poly_ind], this_piece])\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/smart_repair.py:496: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  geometries_df[\"num components orig\"][ind] = num_components(geometries0_df[\"geometry\"][ind])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 0it [00:00, ?it/s]\n",
      "Gaps to fill: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "hdist = smart_repair(hdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 118/118 [00:00<00:00, 317.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maup.doctor(hdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it was 4326 so we have to change it to 4269 first\n",
    "hdist = hdist.to_crs('EPSG:4269')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 118/118 [00:00<00:00, 263.61it/s]\n",
      "100%|███████████████████████████████████████████████| 118/118 [00:06<00:00, 19.02it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "precincts_to_hdist_assignment = maup.assign(vest20.geometry, hdist.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest20[\"HDIST\"] = precincts_to_hdist_assignment.apply(lambda t: t + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get districts assignment and put it into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rename columns by convention.  For example, see: <br>\n",
    "[https://github.com/mggg-states/PA-shapefiles](https://github.com/mggg-states/PA-shapefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'P0020001': 'TOTPOP', 'P0020002': 'HISP', 'P0020005': 'NH_WHITE', 'P0020006': 'NH_BLACK', 'P0020007': 'NH_AMIN',\n",
    "                    'P0020008': 'NH_ASIAN', 'P0020009': 'NH_NHPI', 'P0020010': 'NH_OTHER', 'P0020011': 'NH_2MORE',\n",
    "                    'P0040001': 'VAP', 'P0040002': 'HVAP', 'P0040005': 'WVAP', 'P0040006': 'BVAP', 'P0040007': 'AMINVAP',\n",
    "                                        'P0040008': 'ASIANVAP', 'P0040009': 'NHPIVAP', 'P0040010': 'OTHERVAP', 'P0040011': '2MOREVAP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest20.rename(columns=rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEFP20', 'COUNTYFP20', 'VTDST20', 'GEOID20', 'NAME20', 'G20PREDBID',\n",
       "       'G20PRERTRU', 'G20PRELJOR', 'G20PREGHAW', 'G20PREACAR', 'G20PRESLAR',\n",
       "       'G20USSDDUR', 'G20USSRCUR', 'G20USSIWIL', 'G20USSLMAL', 'G20USSGBLA',\n",
       "       'geometry', 'TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN',\n",
       "       'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK',\n",
       "       'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP',\n",
       "       'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP',\n",
       "       '2MOREVAP', 'CD', 'SEND', 'HDIST'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest20.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other candidates are from other parties.  We'll drop them . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the election columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(original, year):\n",
    "    party = original[6]\n",
    "    if party == 'R' or party == 'D':\n",
    "        return original[3:6] + year + original[6]\n",
    "    else:\n",
    "        return original[3:6] + year + 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_col = vest20.columns[5:16]\n",
    "new_col = [rename(i, '20') for i in original_col]\n",
    "rename_dict = dict(zip(original_col, new_col))\n",
    "vest20 = vest20.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add all the other party column to one column with suffix \"O\" for other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/cd_m04yx2nqfk8k9ljzt2xc80000gn/T/ipykernel_33670/738118509.py:1: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  vest20 = vest20.groupby(level=0, axis=1).sum()\n"
     ]
    }
   ],
   "source": [
    "vest20 = vest20.groupby(level=0, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2MOREVAP', 'AMINVAP', 'ASIANVAP', 'BVAP', 'CD', 'COUNTYFP20',\n",
       "       'GEOID20', 'HDIST', 'HISP', 'HVAP', 'H_2MORE', 'H_AMIN', 'H_ASIAN',\n",
       "       'H_BLACK', 'H_NHPI', 'H_OTHER', 'H_WHITE', 'NAME20', 'NHPIVAP',\n",
       "       'NH_2MORE', 'NH_AMIN', 'NH_ASIAN', 'NH_BLACK', 'NH_NHPI', 'NH_OTHER',\n",
       "       'NH_WHITE', 'OTHERVAP', 'PRE20D', 'PRE20O', 'PRE20R', 'SEND',\n",
       "       'STATEFP20', 'TOTPOP', 'USS20D', 'USS20O', 'USS20R', 'VAP', 'VTDST20',\n",
       "       'WVAP', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest20.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some checks to make sure that the population values are nearly the same in each district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758905\n",
      "749190\n",
      "[758905, 749190, 754269, 754380, 754242, 756238, 745883, 752200, 754527, 753930, 753542, 756658, 753908, 752848, 752707, 757898, 751183]\n"
     ]
    }
   ],
   "source": [
    "print(vest20.loc[vest20[\"CD\"] == 1, \"TOTPOP\"].sum())\n",
    "print(vest20.loc[vest20[\"CD\"] == 2, \"TOTPOP\"].sum())\n",
    "pop_vals = [vest20.loc[vest20[\"CD\"] == n, \"TOTPOP\"].sum() for n in range(1, 18)]\n",
    "print(pop_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = gpd.GeoDataFrame(vest20, crs=\"EPSG:4269\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 IL Election Data Projected to 2020 VTDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18 = gpd.read_file('./il_vest_18/il_vest_18.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEFP20', 'COUNTYFP20', 'VTDST20', 'GEOID20', 'NAME20', 'G18GOVDPRI',\n",
       "       'G18GOVRRAU', 'G18GOVCMCC', 'G18GOVLJAC', 'G18ATGDRAO', 'G18ATGRHAR',\n",
       "       'G18ATGLHAR', 'G18SOSDWHI', 'G18SOSRHEL', 'G18SOSLDUT', 'G18COMDMEN',\n",
       "       'G18COMRSEN', 'G18COMLBAL', 'G18TREDFRE', 'G18TRERDOD', 'G18TRELLEH',\n",
       "       'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/cd_m04yx2nqfk8k9ljzt2xc80000gn/T/ipykernel_33670/2417531403.py:6: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  vest18 = vest18.groupby(level=0, axis=1).sum()\n"
     ]
    }
   ],
   "source": [
    "vest18 = gpd.read_file('./il_vest_18/il_vest_18.shp')\n",
    "original_col = vest18.columns[5:-1]\n",
    "new_col = [rename(i, '18') for i in original_col]\n",
    "rename_dict = dict(zip(original_col, new_col))\n",
    "vest18 = vest18.rename(columns=rename_dict)\n",
    "vest18 = vest18.groupby(level=0, axis=1).sum()\n",
    "col_name = list(set(new_col))\n",
    "col_name.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vest18 = gpd.GeoDataFrame(vest18, crs=\"EPSG:4269\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 369978/369978 [02:39<00:00, 2314.55it/s]\n",
      "100%|███████████████████████████████████████| 369978/369978 [03:49<00:00, 1611.03it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "# convert 2018 pricinct to block\n",
    "vest18_to_block_assginment = maup.assign(vest18.geometry, population_df.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "block18 = population_df[['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "block18[col_name] = vest18[col_name].groupby(vest18_to_block_assginment).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10083/10083 [00:33<00:00, 303.79it/s]\n",
      "100%|█████████████████████████████████████████| 10083/10083 [00:03<00:00, 3321.66it/s]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df = df[df.area > area_cutoff].reset_index(drop=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/intersections.py:48: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/opt/anaconda3/lib/python3.9/site-packages/maup/assign.py:38: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    }
   ],
   "source": [
    "clock18_to_pricinct_assginment = maup.assign(block18.geometry, election_df.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df[col_name] = vest18[col_name].groupby(clock18_to_pricinct_assginment).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/cd_m04yx2nqfk8k9ljzt2xc80000gn/T/ipykernel_33670/834950066.py:1: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  election_df = election_df.groupby(level=0, axis=1).sum()\n"
     ]
    }
   ],
   "source": [
    "election_df = election_df.groupby(level=0, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = election_df[[\n",
    "    'STATEFP20',\n",
    "    'COUNTYFP20',\n",
    "    'VTDST20',\n",
    "    'GEOID20',\n",
    "    'NAME20',\n",
    "    'CD',\n",
    "    'SEND',\n",
    "    'HDIST',\n",
    "    'TOTPOP',\n",
    "    'NH_2MORE',\n",
    "    'NH_AMIN',\n",
    "    'NH_ASIAN',\n",
    "    'NH_BLACK',\n",
    "    'NH_NHPI',\n",
    "    'NH_OTHER',\n",
    "    'NH_WHITE',\n",
    "    'HISP',\n",
    "    'H_AMIN',\n",
    "    'H_ASIAN',\n",
    "    'H_BLACK',\n",
    "    'H_NHPI',\n",
    "    'H_OTHER',\n",
    "    'H_WHITE',\n",
    "    'H_2MORE',\n",
    "    'VAP',\n",
    "    'HVAP',\n",
    "    'WVAP',\n",
    "    'BVAP',\n",
    "    'AMINVAP',\n",
    "    'ASIANVAP',\n",
    "    'NHPIVAP',\n",
    "    'OTHERVAP',\n",
    "    '2MOREVAP',\n",
    "    'ATG18D',\n",
    "    'ATG18R',\n",
    "    'ATG18O',\n",
    "    'PRE20D',\n",
    "    'PRE20R',\n",
    "    'PRE20O',\n",
    "    'SOS18D',\n",
    "    'SOS18R',\n",
    "    'SOS18O',\n",
    "    'COM18D',\n",
    "    'COM18R',\n",
    "    'COM18O',\n",
    "    'GOV18D',\n",
    "    'GOV18R',\n",
    "    'GOV18O',\n",
    "    'TRE18D',\n",
    "    'TRE18R',\n",
    "    'TRE18O',\n",
    "    'USS20D',\n",
    "    'USS20R',\n",
    "    'USS20O',\n",
    "    'geometry'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = gpd.GeoDataFrame(election_df, crs=\"EPSG:4269\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.to_file(\"./IL/IL.shp\")\n",
    "\n",
    "shp_file = gpd.read_file('./IL/IL.shp')\n",
    "\n",
    "shp_file.to_file('./IL/IL.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/gerrychain/graph/graph.py:262: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  areas = df.geometry.area.to_dict()\n"
     ]
    }
   ],
   "source": [
    "from gerrychain import Graph\n",
    "\n",
    "#Only do once to build json and read from file when generating ensembles\n",
    "graph = Graph.from_file(\"./IL/IL.shp\", ignore_errors=True)\n",
    "graph.to_json(\"./IL/IL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maup",
   "language": "python",
   "name": "maup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
